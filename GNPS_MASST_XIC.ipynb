{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import pymzml\n",
    "import os\n",
    "import shutil\n",
    "from contextlib import closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, local_filename):\n",
    "    # NOTE the stream=True parameter below\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                # If you have chunk encoded response uncomment if\n",
    "                # and set chunk_size parameter to None.\n",
    "                #if chunk: \n",
    "                f.write(chunk)\n",
    "\n",
    "def process_masst_xic(input_results_df):\n",
    "    ms2_records = input_results_df.to_dict(orient=\"records\")\n",
    "    for record in ms2_records:\n",
    "        try:\n",
    "            # Making data file available\n",
    "            ftp_url = \"ftp://massive.ucsd.edu/\" + record[\"filename\"][2:]\n",
    "            local_filename = os.path.basename(record[\"filename\"])\n",
    "            proxy_url = \"https://gnps-external.ucsd.edu/massiveftpproxy?ftppath={}\".format(ftp_url)\n",
    "            \n",
    "            filename, file_extension = os.path.splitext(local_filename)\n",
    "            if file_extension == \".mzML\":\n",
    "                continue\n",
    "            \n",
    "            download_file(proxy_url, local_filename)\n",
    "            \n",
    "            # Converting\n",
    "            filename, file_extension = os.path.splitext(local_filename)\n",
    "            if file_extension == \".mzXML\":\n",
    "                # Converting\n",
    "                new_local_filename = filename + \".mzML\"\n",
    "                !FileConverter -in $local_filename -out $new_local_filename\n",
    "                os.remove(local_filename)\n",
    "                local_filename = new_local_filename\n",
    "\n",
    "            # Finding the scan\n",
    "            run = pymzml.run.Reader(local_filename)\n",
    "\n",
    "            target_scan = record[\"filescan\"]\n",
    "            for spectrum in run:\n",
    "                if str(spectrum.ID) == str(target_scan):\n",
    "                    selected_precursors = spectrum.selected_precursors\n",
    "                    precursor_dict = selected_precursors[0]\n",
    "                    precursor_mz = precursor_dict[\"mz\"]\n",
    "                    precursor_i = precursor_dict[\"i\"]\n",
    "\n",
    "                    record[\"precursor_mz\"] = precursor_mz\n",
    "                    record[\"precursor_i\"] = precursor_i\n",
    "                    record[\"rt\"] = spectrum.scan_time_in_minutes()        \n",
    "\n",
    "            # Perform XIC\n",
    "            target_mz = record[\"precursor_mz\"]\n",
    "            lower_rt = record[\"rt\"] - 0.1\n",
    "            upper_rt = record[\"rt\"] + 0.1\n",
    "            run = pymzml.run.Reader(local_filename, MS_precisions={1 : 5e-6, 2 : 20e-6})\n",
    "            time_dependent_intensities = []\n",
    "\n",
    "            for spectrum in run:\n",
    "                spectrum_rt = float(spectrum.scan_time_in_minutes())\n",
    "                if spectrum_rt < lower_rt or spectrum_rt > upper_rt:\n",
    "                    continue\n",
    "\n",
    "                if spectrum.ms_level == 1:\n",
    "                    has_peak_matches = spectrum.has_peak(target_mz)\n",
    "                    if has_peak_matches != []:\n",
    "                        for mz, I in has_peak_matches:\n",
    "                            time_dependent_intensities.append(\n",
    "                                [spectrum.scan_time_in_minutes(), I, mz]\n",
    "                            )\n",
    "\n",
    "            intensity = sum([peak[2] for peak in time_dependent_intensities])\n",
    "            record[\"xic_sum\"] = (intensity)\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print(record)\n",
    "\n",
    "        os.remove(local_filename)\n",
    "\n",
    "    return pd.DataFrame(ms2_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Attention, change this Task ID to your job!\n",
    "\n",
    "GNPS_MASST_job = \"7e9615544d1441319ab525930ebf40cd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Data. Data will appear in specs_ms.mgf file\n",
    "masst_data_url = \"https://gnps.ucsd.edu/ProteoSAFe/DownloadResultFile?task={}&block=main&file=all_dataset_spectra_matches/\".format(GNPS_MASST_job)\n",
    "df = pd.read_csv(masst_data_url, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do stuff with it\n",
    "\n",
    "enriched_df = process_masst_xic(df)\n",
    "\n",
    "enriched_df.to_csv(\"masst_xic.tsv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
